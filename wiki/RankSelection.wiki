#summary Giving more importance to recent estimates

[Introduction] | [TOC Table of Contents] | [RankSelectionWeights NEXT]

One issue with the previous method is all velocities are considered, which can be problematic when methodologies change. Let's say for example a new tool was introduced to increase productivity. In the long term everyone will get work done faster, but until ramp-up on the tool is complete, developers will be slowed down. Preparing a schedule with all previous estimates will dampen the new tool's impact and the schedule will possibly be infeasible. This can be fixed by using a weighted average giving more importance to recent estimates.


= Using the Equation =

This equation determines the weight for a given rank. _n_ is the number of items in the list and _r_ is the "aggressiveness" of the most recent estimates. See [RankSelectionWeights this page] for more information and to see how it was derived.

http://estimate-normalizer.googlecode.com/svn/web/probability-equation/7.png

Previously we simply calculated the average velocity as follows:

http://estimate-normalizer.googlecode.com/svn/web/probability-equation/Average.png

With the weight function, we do it this way instead:

http://estimate-normalizer.googlecode.com/svn/web/probability-equation/WeightedAverage.png

Note that we don't need to divide by anything as the weight function is already normalized, one of the nice things about enforcing the area under the curve to be one!


= An Example =

Let's apply this to the sample data from the introduction. We add the weights and multiply them by the velocities.

|| *Task* || *Estimate* || *Actual* || *Velocity* || *Weight* || *Velocity x Weight* ||
|| 1 || 11.6 || 16.9 || 1.46 || 0.1736 || .253 ||
|| 2 || 11.2 || 17.4 || 1.55 || 0.1597 || .248 ||
|| 3 || 12.5 || 17.6 || 1.41 || 0.1458 || .206 ||
|| 4 || 7.9 || 11.5 || 1.46 || 0.1319 || .193 ||
|| 5 || 10 || 15.8 || 1.58 || 0.1181 || .187 ||
|| 6 || 14.5 || 21 || 1.45 || 0.1042 || .151 ||
|| 7 || 13.1 || 20 || 1.53 || 0.0903 || .138 ||
|| 8 || 8.2 || 11.9 || 1.45 || 0.0764 || .111 ||
|| 9 || 5.6 || 8.4 || 1.5 || 0.0625 || .094 ||
|| 10 || 6.7 || 10.4 || 1.55 || 0.0486 || .075 ||
||       ||        ||          ||         || *SUM*    || 1.656 ||

You may notice our weighted average velocity is higher than any of our velocities, which doesn't make much sense... This is due to the number of data points we're using, which gives a weight sum of about 1.1. The area under the curve really is 1, but due to our small number of data points it's not very precise. As we would add more data points their sum would converge to 1. This can be verified by integrating _f(x)_ and evaluating it at _n-1_ and _0_.

[Introduction] | [TOC Table of Contents] | [RankSelectionWeights NEXT]
